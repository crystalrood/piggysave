{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sys;\n",
    "#reload(sys);\n",
    "#sys.setdefaultencoding(\"utf8\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import numpy as np\n",
    "import csv, sys\n",
    "import base64\n",
    "import datefinder\n",
    "import datetime\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import quopri\n",
    "#uri = 'mongodb://heroku_4jtg3rvf:r9nq5ealpnfrlda5la4fj8r192@ds161503.mlab.com:61503/heroku_4jtg3rvf'\n",
    "#client = MongoClient(uri)\n",
    "#db = client['heroku_4jtg3rvf']\n",
    "\n",
    "client = MongoClient('mongodb://localhost:27017/test')\n",
    "db = client.test\n",
    "import email\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-5-eca25edc13e7>, line 181)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-eca25edc13e7>\"\u001b[0;36m, line \u001b[0;32m181\u001b[0m\n\u001b[0;31m    try:\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "\n",
    "messages = db.messages\n",
    "messages = pd.DataFrame(list(messages.find()))\n",
    " \n",
    "#setting up dataframe for scraping\n",
    "columns = ['thread_id','email', 'retailer', 'date', 'order_num', 'zipcode', 'url', 'item_num', 'quantity', 'color', 'price', 'image_url', 'item_name']\n",
    "df_items = pd.DataFrame(columns=columns)\n",
    "\n",
    "# ###if there are actually messages in the DB, then go ahead and proceed\n",
    "if len(messages) > 0:\n",
    "    # all this code below is to remove duplicates\n",
    "\tdel messages['_id']\n",
    "\tdel messages['createdAt']\n",
    "\tdel messages['date_extracted']\n",
    "\tdel messages['__v']\n",
    "\tdel messages['updatedAt']\n",
    "\tdel messages['status']\n",
    "\tmessages = messages.drop_duplicates()\n",
    "    \n",
    "\tfor index, row in messages.iterrows():\n",
    "\n",
    "\t    # ###decodes message and splits into lines\n",
    "\t    msg_decoded = quopri.decodestring(base64.urlsafe_b64decode(row['encoded_message'].encode('utf8', 'replace')))\n",
    "\t    msg_decoded = msg_decoded.decode('ISO-8859-1')\n",
    "\t    string = msg_decoded.split('\\r\\n')\n",
    "\n",
    "\t    # ###EMAIL of user\n",
    "\t    email = row['email']\n",
    "\n",
    "\n",
    "\t    # ###DATE email was sent\n",
    "\t    recieved = 'received'\n",
    "\t    for idx, text in enumerate(string):\n",
    "\t        if recieved in text.lower():\n",
    "\t            break;\n",
    "\n",
    "\t    matches = datefinder.find_dates(string[idx+1])\n",
    "\t    for match in matches:\n",
    "\t        date = match.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "\t    # ###RETAILER of order\n",
    "\t    retailers = ['nordstrom']\n",
    "\n",
    "\t    # ####getting retailer information\n",
    "\t    for num in retailers:\n",
    "\t        for idx, text in enumerate(string):\n",
    "\t            if num in text.lower():\n",
    "\t                retailer = num\n",
    "\t                break;\n",
    "\n",
    "\n",
    "\t    order_num = ['order number']\n",
    "\n",
    "\t    for num in order_num:\n",
    "\t        find = False\n",
    "\t        for idx, text in enumerate(string):\n",
    "\t            if num in text.lower():\n",
    "\t                find = True\n",
    "\t                text = text\n",
    "\t                # print(idx, text)\n",
    "\t                break;\n",
    "\t        if find:\n",
    "\t            break\n",
    "\n",
    "\t    order_number = ''\n",
    "\n",
    "\n",
    "\t    try:\n",
    "\t        order_number = re.findall(r'\\d+', text )\n",
    "\t        order_number = order_number[1]\n",
    "\t    except:\n",
    "\t        order_number = 'not available'\n",
    "\t        pass\n",
    "\n",
    "\n",
    "\t    # ####ZIPCODE if retailer is nordstrom     \n",
    "\t    try:\n",
    "\t        billing = ['billing address start']\n",
    "\t        for bill in billing:\n",
    "\t            find = False\n",
    "\t            for bill_idx, text in enumerate(string):\n",
    "\t                if bill in text.lower():\n",
    "\t                    find = True\n",
    "\t                    #print(bill_idx, text)\n",
    "\t                    break;\n",
    "\t            if find:\n",
    "\t                break\n",
    "\t        address = ''\n",
    "\n",
    "\t        for i in range (0,40):\n",
    "\t            address += string[bill_idx+i] + ' '\n",
    "\n",
    "\t        match = re.search(r'\\b\\d{5}(?:-\\d{4})?\\b',  address)\n",
    "\t        zip_code = match.group(0)\n",
    "\t        #print(\"zipcode\" + zip_code)\n",
    "\n",
    "\t    except:\n",
    "\t        address_string = 'not available'\n",
    "\t        zip_code = 'not available'\n",
    "\t        pass\n",
    "\n",
    "\t    # ####EMAIL THREAD ID\n",
    "\t    thread_id = row['thread_id']\n",
    "\t    #print(thread_id)\n",
    "\n",
    "\t    #print(\"order number\" +order_number)\n",
    "\t        ###################################################################\n",
    "\t    ###### GETTING ITEMS INFORMATION  #################################\n",
    "\t    ###################################################################\n",
    "\n",
    "\n",
    "\t    order_num = ['description:']\n",
    "\n",
    "\n",
    "\t    # print order_num\n",
    "\t    #getting order num\n",
    "\t    line_number = []\n",
    "\t    find = False\n",
    "\t    for idx, text in enumerate(string):\n",
    "\t        if 'description:' in text.lower():\n",
    "\t            find = True\n",
    "\t            text = text\n",
    "\t            line_number.append(idx)\n",
    "\t            description_text = ''\n",
    "\t            for x in range(idx, idx+200):\n",
    "\t                description_text += string[x]\n",
    "\n",
    "\t            # ###ITEM URL\n",
    "\t            soup = BeautifulSoup(description_text, \"html.parser\")\n",
    "\t            url = soup.find_all('a', href=True)[0]['href']\n",
    "\t            r = requests.get(url) \n",
    "\t            url = r.url.split(\"?\")[0]\n",
    "\t            #print(r.url)\n",
    "\n",
    "\n",
    "\t            # ###ITEM NUMBER\n",
    "\t            index1 = description_text.find('\\t#')\n",
    "\t            item_number=''\n",
    "\t            for x in range(index1, index1+40):\n",
    "\t                if description_text[x].isdigit():\n",
    "\t                    item_number += description_text[x]\n",
    "\t            #print(item_number)\n",
    "\n",
    "\n",
    "\t            # ###ITEM COLOR\n",
    "\t            index2 = description_text.find('Color:')\n",
    "\t            color=''\n",
    "\t            for x in range(index2, index2+100):\n",
    "\t                color += description_text[x]\n",
    "\n",
    "\t            soup = BeautifulSoup(color, \"html.parser\")\n",
    "\t            color_name = soup.find('span').text\n",
    "\n",
    "\t            #print(color_name)\n",
    "\n",
    "\t            # ###ITEM PRICE \n",
    "\t            index3 = description_text.find('Price:')\n",
    "\t            price=''\n",
    "\t            for x in range(index3, index3+100):\n",
    "\t                price += description_text[x]\n",
    "\n",
    "\t            soup = BeautifulSoup(price, \"html.parser\")\n",
    "\t            price_name = soup.find('span').text\n",
    "\t            #print(price_name)\n",
    "\n",
    "\t            # ###ITEM QUANTITY\n",
    "\t            index4 = description_text.find('Qty:')\n",
    "\t            quantity=''\n",
    "\t            for x in range(index4, index4+100):\n",
    "\t                quantity += description_text[x]\n",
    "\n",
    "\t            soup = BeautifulSoup(quantity, \"html.parser\")\n",
    "\t            quantity_name = soup.find('span').text\n",
    "\t            #print(quantity_name)\n",
    "\n",
    "\n",
    "                  \n",
    "                #trying to bring in additional information about the product\n",
    "                \n",
    "                try: \n",
    "                    html2 = requests.get(url).text\n",
    "                    soup2 = BeautifulSoup(html2, \"html.parser\")\n",
    "                    div = soup2.find_all('div', {\"data-element\": \"product-title\"})\n",
    "                    item_name = div[0].text\n",
    "                    img = soup2.find_all('img', {\"name\": \"main-gallery-image\"})\n",
    "                    image_url = img[0]['src'].encode('utf-8')\n",
    "                except:\n",
    "                    item_name = 'could not find'\n",
    "                    image_url = 'could not find'\n",
    "                \n",
    "                #inserting fow into dataframe\n",
    "\t            df_items.loc[len(df_items)]=[\n",
    "\t                    thread_id, \n",
    "\t                    email, \n",
    "\t                    retailer, \n",
    "\t                    date, \n",
    "\t                    order_number, \n",
    "\t                    zip_code, \n",
    "\t                    url,\n",
    "\t                    item_number,\n",
    "\t                    quantity_name,\n",
    "\t                    color_name,\n",
    "\t                    price_name,\n",
    "                        image_url,\n",
    "                        item_name\n",
    "\t                    ]\n",
    "\t            df_items[['price']] = df_items[['price']].replace('[\\$,]','',regex=True).astype(float)\n",
    "\t            df_items = df_items[(df_items.order_num != 'not available') \\\n",
    "\t                                &(df_items.price > 0)].reset_index(drop=True)\n",
    "\n",
    "\t    today = datetime.date.today()\n",
    "\t    for index, row in df_items.iterrows():\n",
    "\t        dic = {\n",
    "\t           'thread_id': row['thread_id'],\n",
    "\t           'email': row['email'],\n",
    "\t           'retailer': row['retailer'],\n",
    "\t           'date': row['date'],\n",
    "\t           'order_num': row['order_num'],\n",
    "\t           'zipcode': row['zipcode'],\n",
    "\t           'url': row['url'],\n",
    "\t           'item_num': row['item_num'],\n",
    "\t           'quantity': row['quantity'],\n",
    "\t           'color': row['color'],\n",
    "\t           'price': row['price'],\n",
    "\t           'last_date_checked': str(today),\n",
    "               'image_url': row['image_url'],\n",
    "               'item_name': row['item_name'],\n",
    "\t           'status': 'tracking'\n",
    "\t          }\n",
    "\t        #result = db.order_info_item_scrapes.insert_one(dic)\n",
    "\n",
    "\n",
    "\t    #this changes the status from \"need to scrape\" to \"scraped\" in\n",
    "\t    #the messages database\n",
    "\t    #for index, row in messages.iterrows():\n",
    "\t       # db.messages.update_many(\n",
    "\t        #    {\"thread_id\": row['thread_id']},\n",
    "\t        #    {\"$set\": {\"status\": \"scraped\"}}\n",
    "\t        #)\n",
    "\n",
    "\n",
    "\t    print('testedandsuccess')\n",
    "\n",
    "\n",
    "\t    #print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TabError",
     "evalue": "inconsistent use of tabs and spaces in indentation (<ipython-input-6-a00bbb8b90df>, line 204)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-a00bbb8b90df>\"\u001b[0;36m, line \u001b[0;32m204\u001b[0m\n\u001b[0;31m    try:\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mTabError\u001b[0m\u001b[0;31m:\u001b[0m inconsistent use of tabs and spaces in indentation\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sys;\n",
    "#reload(sys);\n",
    "#sys.setdefaultencoding(\"utf8\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import numpy as np\n",
    "import csv, sys\n",
    "import base64\n",
    "import datefinder\n",
    "import datetime\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import quopri\n",
    "#uri = 'mongodb://heroku_4jtg3rvf:r9nq5ealpnfrlda5la4fj8r192@ds161503.mlab.com:61503/heroku_4jtg3rvf'\n",
    "#client = MongoClient(uri)\n",
    "#db = client['heroku_4jtg3rvf']\n",
    "\n",
    "client = MongoClient('mongodb://localhost:27017/test')\n",
    "db = client.test\n",
    "import email\n",
    "\n",
    "\n",
    "messages = db.messages\n",
    "messages = pd.DataFrame(list(messages.find()))\n",
    " \n",
    "#setting up dataframe for scraping\n",
    "columns = ['thread_id','email', 'retailer', 'date', 'order_num', 'zipcode', 'url', 'item_num', 'quantity', 'color', 'price']\n",
    "df_items = pd.DataFrame(columns=columns)\n",
    "\n",
    "# ###if there are actually messages in the DB, then go ahead and proceed\n",
    "if len(messages) > 0:\n",
    "    # all this code below is to remove duplicates\n",
    "\tdel messages['_id']\n",
    "\tdel messages['createdAt']\n",
    "\tdel messages['date_extracted']\n",
    "\tdel messages['__v']\n",
    "\tdel messages['updatedAt']\n",
    "\tdel messages['status']\n",
    "\tmessages = messages.drop_duplicates()\n",
    "    \n",
    "\tfor index, row in messages.iterrows():\n",
    "\n",
    "\t    # ###decodes message and splits into lines\n",
    "\t    msg_decoded = quopri.decodestring(base64.urlsafe_b64decode(row['encoded_message'].encode('utf8', 'replace')))\n",
    "\t    msg_decoded = msg_decoded.decode('ISO-8859-1')\n",
    "\t    string = msg_decoded.split('\\r\\n')\n",
    "\n",
    "\t    # ###EMAIL of user\n",
    "\t    email = row['email']\n",
    "\n",
    "\n",
    "\t    # ###DATE email was sent\n",
    "\t    recieved = 'received'\n",
    "\t    for idx, text in enumerate(string):\n",
    "\t        if recieved in text.lower():\n",
    "\t            break;\n",
    "\n",
    "\t    matches = datefinder.find_dates(string[idx+1])\n",
    "\t    for match in matches:\n",
    "\t        date = match.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "\t    # ###RETAILER of order\n",
    "\t    retailers = ['nordstrom']\n",
    "\n",
    "\t    # ####getting retailer information\n",
    "\t    for num in retailers:\n",
    "\t        for idx, text in enumerate(string):\n",
    "\t            if num in text.lower():\n",
    "\t                retailer = num\n",
    "\t                break;\n",
    "\n",
    "\n",
    "\t    order_num = ['order number']\n",
    "\n",
    "\t    for num in order_num:\n",
    "\t        find = False\n",
    "\t        for idx, text in enumerate(string):\n",
    "\t            if num in text.lower():\n",
    "\t                find = True\n",
    "\t                text = text\n",
    "\t                # print(idx, text)\n",
    "\t                break;\n",
    "\t        if find:\n",
    "\t            break\n",
    "\n",
    "\t    order_number = ''\n",
    "\n",
    "\n",
    "\t    try:\n",
    "\t        order_number = re.findall(r'\\d+', text )\n",
    "\t        order_number = order_number[1]\n",
    "\t    except:\n",
    "\t        order_number = 'not available'\n",
    "\t        pass\n",
    "\n",
    "\n",
    "\t    # ####ZIPCODE if retailer is nordstrom     \n",
    "\t    try:\n",
    "\t        billing = ['billing address start']\n",
    "\t        for bill in billing:\n",
    "\t            find = False\n",
    "\t            for bill_idx, text in enumerate(string):\n",
    "\t                if bill in text.lower():\n",
    "\t                    find = True\n",
    "\t                    #print(bill_idx, text)\n",
    "\t                    break;\n",
    "\t            if find:\n",
    "\t                break\n",
    "\t        address = ''\n",
    "\n",
    "\t        for i in range (0,40):\n",
    "\t            address += string[bill_idx+i] + ' '\n",
    "\n",
    "\t        match = re.search(r'\\b\\d{5}(?:-\\d{4})?\\b',  address)\n",
    "\t        zip_code = match.group(0)\n",
    "\t        #print(\"zipcode\" + zip_code)\n",
    "\n",
    "\t    except:\n",
    "\t        address_string = 'not available'\n",
    "\t        zip_code = 'not available'\n",
    "\t        pass\n",
    "\n",
    "\t    # ####EMAIL THREAD ID\n",
    "\t    thread_id = row['thread_id']\n",
    "\t    #print(thread_id)\n",
    "\n",
    "\t    #print(\"order number\" +order_number)\n",
    "\t        ###################################################################\n",
    "\t    ###### GETTING ITEMS INFORMATION  #################################\n",
    "\t    ###################################################################\n",
    "\n",
    "\n",
    "\t    order_num = ['description:']\n",
    "\n",
    "\n",
    "\t    # print order_num\n",
    "\t    #getting order num\n",
    "\t    line_number = []\n",
    "\t    find = False\n",
    "\t    for idx, text in enumerate(string):\n",
    "\t        if 'description:' in text.lower():\n",
    "\t            find = True\n",
    "\t            text = text\n",
    "\t            line_number.append(idx)\n",
    "\t            description_text = ''\n",
    "\t            for x in range(idx, idx+200):\n",
    "\t                description_text += string[x]\n",
    "\n",
    "\t            # ###ITEM URL\n",
    "\t            soup = BeautifulSoup(description_text, \"html.parser\")\n",
    "\t            url = soup.find_all('a', href=True)[0]['href']\n",
    "\t            r = requests.get(url) \n",
    "\t            url = r.url.split(\"?\")[0]\n",
    "\t            #print(r.url)\n",
    "\n",
    "\n",
    "\t            # ###ITEM NUMBER\n",
    "\t            index1 = description_text.find('\\t#')\n",
    "\t            item_number=''\n",
    "\t            for x in range(index1, index1+40):\n",
    "\t                if description_text[x].isdigit():\n",
    "\t                    item_number += description_text[x]\n",
    "\t            #print(item_number)\n",
    "\n",
    "\n",
    "\t            # ###ITEM COLOR\n",
    "\t            index2 = description_text.find('Color:')\n",
    "\t            color=''\n",
    "\t            for x in range(index2, index2+100):\n",
    "\t                color += description_text[x]\n",
    "\n",
    "\t            soup = BeautifulSoup(color, \"html.parser\")\n",
    "\t            color_name = soup.find('span').text\n",
    "\n",
    "\t            #print(color_name)\n",
    "\n",
    "\t            # ###ITEM PRICE \n",
    "\t            index3 = description_text.find('Price:')\n",
    "\t            price=''\n",
    "\t            for x in range(index3, index3+100):\n",
    "\t                price += description_text[x]\n",
    "\n",
    "\t            soup = BeautifulSoup(price, \"html.parser\")\n",
    "\t            price_name = soup.find('span').text\n",
    "\t            #print(price_name)\n",
    "\n",
    "\t            # ###ITEM QUANTITY\n",
    "\t            index4 = description_text.find('Qty:')\n",
    "\t            quantity=''\n",
    "\t            for x in range(index4, index4+100):\n",
    "\t                quantity += description_text[x]\n",
    "\n",
    "\t            soup = BeautifulSoup(quantity, \"html.parser\")\n",
    "\t            quantity_name = soup.find('span').text\n",
    "\t            #print(quantity_name)\n",
    "\n",
    "                #trying to bring in additional information about the product\n",
    "                \n",
    "                try:\n",
    "                    html2 = requests.get(url).text\n",
    "                    soup2 = BeautifulSoup(html2, \"html.parser\")\n",
    "                    div = soup2.find_all('div', {\"data-element\": \"product-title\"})\n",
    "                    item_name = div[0].text\n",
    "                    img = soup2.find_all('img', {\"name\": \"main-gallery-image\"})\n",
    "                    image_url = img[0]['src'].encode('utf-8')\n",
    "                except:\n",
    "                    item_name = 'could not find'\n",
    "                    image_url = 'could not find'\n",
    "                \n",
    "                #inserting fow into dataframe\n",
    "\t            df_items.loc[len(df_items)]=[\n",
    "\t                    thread_id, \n",
    "\t                    email, \n",
    "\t                    retailer, \n",
    "\t                    date, \n",
    "\t                    order_number, \n",
    "\t                    zip_code, \n",
    "\t                    url,\n",
    "\t                    item_number,\n",
    "\t                    quantity_name,\n",
    "\t                    color_name,\n",
    "\t                    price_name,\n",
    "                        image_url,\n",
    "                        item_name\n",
    "\t                    ]\n",
    "\t            df_items[['price']] = df_items[['price']].replace('[\\$,]','',regex=True).astype(float)\n",
    "\t            df_items = df_items[(df_items.order_num != 'not available') \\\n",
    "\t                                &(df_items.price > 0)].reset_index(drop=True)\n",
    "\n",
    "\t    today = datetime.date.today()\n",
    "\t    for index, row in df_items.iterrows():\n",
    "\t        dic = {\n",
    "\t           'thread_id': row['thread_id'],\n",
    "\t           'email': row['email'],\n",
    "\t           'retailer': row['retailer'],\n",
    "\t           'date': row['date'],\n",
    "\t           'order_num': row['order_num'],\n",
    "\t           'zipcode': row['zipcode'],\n",
    "\t           'url': row['url'],\n",
    "\t           'item_num': row['item_num'],\n",
    "\t           'quantity': row['quantity'],\n",
    "\t           'color': row['color'],\n",
    "\t           'price': row['price'],\n",
    "\t           'last_date_checked': str(today),\n",
    "               'image_url': row['image_url'],\n",
    "               'item_name': row['item_name'],\n",
    "\t           'status': 'tracking'\n",
    "\t          }\n",
    "\t        #result = db.order_info_item_scrapes.insert_one(dic)\n",
    "\n",
    "\n",
    "\t    #this changes the status from \"need to scrape\" to \"scraped\" in\n",
    "\t    #the messages database\n",
    "\t    for index, row in messages.iterrows():\n",
    "\t        #db.messages.update_many(\n",
    "\t       #     {\"thread_id\": row['thread_id']},\n",
    "\t       #     {\"$set\": {\"status\": \"scraped\"}}\n",
    "\t        #)\n",
    "\n",
    "\n",
    "\t    print('testedandsuccess')\n",
    "\n",
    "\n",
    "\t    #print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
