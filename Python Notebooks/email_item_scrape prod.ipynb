{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import sys;\n",
    "#reload(sys);\n",
    "#sys.setdefaultencoding(\"utf8\")\n",
    "import re\n",
    "import pandas as pd\n",
    "import pprint\n",
    "import numpy as np\n",
    "import csv, sys\n",
    "import base64\n",
    "import datefinder\n",
    "import datetime\n",
    "\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import quopri\n",
    "#uri = 'mongodb://heroku_4jtg3rvf:r9nq5ealpnfrlda5la4fj8r192@ds161503.mlab.com:61503/heroku_4jtg3rvf'\n",
    "#client = MongoClient(uri)\n",
    "#db = client['heroku_4jtg3rvf']\n",
    "\n",
    "client = MongoClient('mongodb://localhost:27017/test')\n",
    "db = client.test\n",
    "import email\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = db.messages\n",
    "messages = pd.DataFrame(list(messages.find()))\n",
    "    \n",
    "# all this code below is to remove duplicates\n",
    "del messages['_id']\n",
    "del messages['createdAt']\n",
    "del messages['date_extracted']\n",
    "del messages['__v']\n",
    "del messages['updatedAt']\n",
    "del messages['status']\n",
    "messages = messages.drop_duplicates()\n",
    "\n",
    "#setting up dataframe for scrapting\n",
    "columns = ['thread_id','email', 'retailer', 'date', 'order_num', 'zipcode', 'url', 'item_num', 'quantity', 'color', 'price']\n",
    "#setting up dataframe\n",
    "df_items = pd.DataFrame(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>thread_id</th>\n",
       "      <th>email</th>\n",
       "      <th>retailer</th>\n",
       "      <th>date</th>\n",
       "      <th>order_num</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>url</th>\n",
       "      <th>item_num</th>\n",
       "      <th>quantity</th>\n",
       "      <th>color</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [thread_id, email, retailer, date, order_num, zipcode, url, item_num, quantity, color, price]\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testedandsuccess\n",
      "testedandsuccess\n",
      "testedandsuccess\n",
      "testedandsuccess\n",
      "testedandsuccess\n",
      "testedandsuccess\n",
      "testedandsuccess\n"
     ]
    }
   ],
   "source": [
    "messages = db.messages\n",
    "messages = pd.DataFrame(list(messages.find()))\n",
    "\n",
    "\n",
    "# ###if there are actually messages in the DB, then go ahead and proceed\n",
    "if len(messages) > 0:\n",
    "    \n",
    "    # all this code below is to remove duplicates\n",
    "    del messages['_id']\n",
    "    del messages['createdAt']\n",
    "    del messages['date_extracted']\n",
    "    del messages['__v']\n",
    "    del messages['updatedAt']\n",
    "    del messages['status']\n",
    "    messages = messages.drop_duplicates()\n",
    "\n",
    "    # ###only filter on emails that need to be scraped\n",
    "    #messages = messages[(messages.status == 'need to scrape')]\n",
    "\n",
    "    #setting up dataframe for scrapting\n",
    "    columns = ['thread_id','email', 'retailer', 'date', 'order_num', 'zipcode', 'url', 'item_num', 'quantity', 'color', 'price']\n",
    "    #setting up dataframe\n",
    "    df_items = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for index, row in messages.iterrows():\n",
    "\n",
    "        # ###decodes message and splits into lines\n",
    "        msg_decoded = quopri.decodestring(base64.urlsafe_b64decode(row['encoded_message'].encode('utf8', 'replace')))\n",
    "        msg_decoded = msg_decoded.decode('ISO-8859-1')\n",
    "        string = msg_decoded.split('\\r\\n')\n",
    "\n",
    "        # ###EMAIL of user\n",
    "        email = row['email']\n",
    "\n",
    "\n",
    "        # ###DATE email was sent\n",
    "        recieved = 'received'\n",
    "        for idx, text in enumerate(string):\n",
    "            if recieved in text.lower():\n",
    "                break;\n",
    "        \n",
    "        matches = datefinder.find_dates(string[idx+1])\n",
    "        for match in matches:\n",
    "            date = match.strftime('%m/%d/%Y')\n",
    "\n",
    "\n",
    "        # ###RETAILER of order\n",
    "        retailers = ['nordstrom']\n",
    "\n",
    "        # ####getting retailer information\n",
    "        for num in retailers:\n",
    "            for idx, text in enumerate(string):\n",
    "                if num in text.lower():\n",
    "                    retailer = num\n",
    "                    break;\n",
    "                    \n",
    "        # ####ORDER NUMBER if retailer is nordstrom            \n",
    "        if retailer == 'nordstrom':\n",
    "            order_num = ['order #']\n",
    "\n",
    "        for num in order_num:\n",
    "            find = False\n",
    "            for idx, text in enumerate(string):\n",
    "                if num in text.lower():\n",
    "                    find = True\n",
    "                    text = text\n",
    "                    # print(idx, text)\n",
    "                    break;\n",
    "            if find:\n",
    "                break\n",
    "\n",
    "        order_number = ''\n",
    "\n",
    "        if retailer == 'nordstrom':\n",
    "            try:\n",
    "                order_number = re.findall(r'\\d+', text )\n",
    "                order_number = order_number[0]\n",
    "            except:\n",
    "                order_number = 'not available'\n",
    "                pass\n",
    "\n",
    "\n",
    "            # ####ZIPCODE if retailer is nordstrom     \n",
    "            try:\n",
    "                if retailer == 'nordstrom':\n",
    "                    billing = ['billing address start']\n",
    "                    for bill in billing:\n",
    "                        find = False\n",
    "                        for bill_idx, text in enumerate(string):\n",
    "                            if bill in text.lower():\n",
    "                                find = True\n",
    "                                #print(bill_idx, text)\n",
    "                                break;\n",
    "                        if find:\n",
    "                            break\n",
    "                    address = ''\n",
    "\n",
    "                    for i in range (0,40):\n",
    "                        address += string[bill_idx+i] + ' '\n",
    "\n",
    "                    match = re.search(r'\\b\\d{5}(?:-\\d{4})?\\b',  address)\n",
    "                    zip_code = match.group(0)\n",
    "                    # print \"zipcode\" + zip_code\n",
    "\n",
    "            except:\n",
    "                address_string = 'not available'\n",
    "                zip_code = 'not available'\n",
    "                pass\n",
    "\n",
    "            # ####EMAIL THREAD ID\n",
    "            thread_id = row['thread_id']\n",
    "\n",
    "\n",
    "            ###################################################################\n",
    "            ###### GETTING ITEMS INFORMATION  #################################\n",
    "            ###################################################################\n",
    "\n",
    "\n",
    "            order_num = ['description:']\n",
    "\n",
    "\n",
    "            # print order_num\n",
    "            #getting order num\n",
    "            line_number = []\n",
    "            find = False\n",
    "            for idx, text in enumerate(string):\n",
    "                if 'description:' in text.lower():\n",
    "                    find = True\n",
    "                    text = text\n",
    "                    line_number.append(idx)\n",
    "                    description_text = ''\n",
    "                    for x in range(idx, idx+200):\n",
    "                        description_text += string[x]\n",
    "\n",
    "                    # ###ITEM URL\n",
    "                    soup = BeautifulSoup(description_text, \"html.parser\")\n",
    "                    url = soup.find_all('a', href=True)[0]['href']\n",
    "                    r = requests.get(url) \n",
    "                   # print(r.url)\n",
    "\n",
    "\n",
    "                    # ###ITEM NUMBER\n",
    "                    index1 = description_text.find('\\t#')\n",
    "                    item_number=''\n",
    "                    for x in range(index1, index1+40):\n",
    "                        if description_text[x].isdigit():\n",
    "                            item_number += description_text[x]\n",
    "                    #print(item_number)\n",
    "\n",
    "\n",
    "                    # ###ITEM COLOR\n",
    "                    index2 = description_text.find('Color:')\n",
    "                    color=''\n",
    "                    for x in range(index2, index2+100):\n",
    "                        color += description_text[x]\n",
    "\n",
    "                    soup = BeautifulSoup(color, \"html.parser\")\n",
    "                    color_name = soup.find('span').text\n",
    "\n",
    "                   # print(color_name)\n",
    "\n",
    "                    # ###ITEM PRICE \n",
    "                    index3 = description_text.find('Price:')\n",
    "                    price=''\n",
    "                    for x in range(index3, index3+100):\n",
    "                        price += description_text[x]\n",
    "\n",
    "                    soup = BeautifulSoup(price, \"html.parser\")\n",
    "                    price_name = soup.find('span').text\n",
    "                    #print(price_name)\n",
    "\n",
    "                    # ###ITEM QUANTITY\n",
    "                    index4 = description_text.find('Qty:')\n",
    "                    quantity=''\n",
    "                    for x in range(index4, index4+100):\n",
    "                        quantity += description_text[x]\n",
    "\n",
    "                    soup = BeautifulSoup(quantity, \"html.parser\")\n",
    "                    quantity_name = soup.find('span').text\n",
    "                    #print(quantity_name)\n",
    "\n",
    "\n",
    "                    #inserting fow into dataframe\n",
    "\n",
    "                    df_items.loc[len(df_items)]=[\n",
    "                            thread_id, \n",
    "                            email, \n",
    "                            retailer, \n",
    "                            date, \n",
    "                            order_number, \n",
    "                            zip_code, \n",
    "                            r.url,\n",
    "                            item_number,\n",
    "                            quantity_name,\n",
    "                            color_name,\n",
    "                            price_name\n",
    "                            ]\n",
    "                    df_items[['price']] = df_items[['price']].replace('[\\$,]','',regex=True).astype(float)\n",
    "                    df_items = df_items[(df_items.order_num != 'not available') \\\n",
    "                                        &(df_items.price > 0)].reset_index(drop=True)\n",
    "\n",
    "        today = datetime.date.today()\n",
    "        for index, row in df_items.iterrows():\n",
    "            dic = {\n",
    "               'thread_id': row['thread_id'],\n",
    "               'email': row['email'],\n",
    "               'retailer': row['retailer'],\n",
    "               'date': row['date'],\n",
    "               'order_num': row['order_num'],\n",
    "               'zipcode': row['zipcode'],\n",
    "               'url': row['url'],\n",
    "               'item_num': row['item_num'],\n",
    "               'quantity': row['quantity'],\n",
    "               'color': row['color'],\n",
    "               'price': row['price'],\n",
    "               'last_date_checked': str(today),\n",
    "               'status': 'tracking'\n",
    "              }\n",
    "            result = db.order_info_item_scrapes.insert_one(dic)\n",
    "  \n",
    "  \n",
    "        #this changes the status from \"need to scrape\" to \"scraped\" in\n",
    "        #the messages database\n",
    "        for index, row in df.iterrows():\n",
    "            db.messages.update_many(\n",
    "                {\"thread_id\": row['thread_id']},\n",
    "                {\"$set\": {\"status\": \"scraped\"}}\n",
    "            )\n",
    "\n",
    "\n",
    "        print('testedandsuccess')\n",
    "\n",
    "\n",
    "        #print df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'thread_id': '1604208710f2fd98',\n",
       " 'email': 'crystal.wesnoski@gmail.com',\n",
       " 'retailer': 'nordstrom',\n",
       " 'date': '12/17/2017',\n",
       " 'order_num': '871467911',\n",
       " 'zipcode': '94085',\n",
       " 'url': 'https://shop.nordstrom.com/s/lancome-visionnaire-correcting-perfecting-collection-195-50-value/4772171?cm_mmc=email_tran-_-121717-_-order_confirm-_-proddescr1&cm_em=',\n",
       " 'item_num': '5479176',\n",
       " 'quantity': '1',\n",
       " 'color': 'No Color',\n",
       " 'price': 127.0,\n",
       " 'last_date_checked': '2018-06-11',\n",
       " 'status': 'tracking'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ###decodes message and splits into lines\n",
    "msg_decoded = quopri.decodestring(base64.urlsafe_b64decode(messages['encoded_message'][1].encode('utf8', 'replace')))\n",
    "msg_decoded = msg_decoded.decode('ISO-8859-1')\n",
    "string = msg_decoded.split('\\r\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
